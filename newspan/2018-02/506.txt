Leading innovators, investors and policymakers offered their visions for artificial intelligence at the New York Times's New Work Summit conference.
In Phoenix, cars are self-navigating the streets. In many homes, people are barking commands at tiny machines, with the machines responding. On our smartphones, apps can now recognize faces in photos and translate from one language to another.
Artificial intelligence is here — and it’s bringing new possibilities, while also raising questions. Do these gadgets and services really behave as advertised? How will they evolve in the years ahead? How quickly will they overhaul the way we live and change the way we do business?
A month after the Chinese electronics giant Huawei suffered a big setback in its quest to sell its high-end smartphones to Americans, the company’s chief for consumer devices, Richard Yu, said he was still optimistic about Huawei’s prospects in the United States.
Huawei is the world’s third-largest seller of smartphones and one of the planet’s biggest suppliers of telecommunications equipment. But it has struggled for years to break into the United States.
A 2012 congressional report said that Huawei’s network gear could be used by Beijing to spy on Americans, effectively cutting the company off from big buyers in the United States. In January, after lawmakers reiterated those concerns in a letter to the Federal Communications Commission, AT&T and Verizon walked away from deals to sell Huawei’s latest phones.
Mike Schroepfer, Facebook’s chief technology officer, offered a glimpse of how the social network is applying artificial intelligence to ward off bad actors and keep its platform free of toxicity.
Calling the fight against rules violators a “cat and mouse game,” Mr. Schroepfer said at the New Work Summit on Tuesday that Facebook’s A.I. efforts had succeeded at certain types of content moderation, such as image classifier algorithms that find and automatically remove nude photos and videos.
But what about using A.I. to curb the spread of fake news? Facebook’s director of artificial intelligence, Yann LeCun, said in 2016 that machine learning algorithms would one day be able to weed out false news on Facebook.
But the company has since added thousands of human content moderators and struck partnerships with human fact-checking organizations. Mr. Schroepfer implied Facebook has learned that A.I. alone would not do the trick, given the sophistication of bad actors who find ways around the platform’s filters.
Mr. Schroepfer also said that human judgment would be required in certain situations, like a comment (“nice jacket”) that could be either an earnest compliment or a sarcastic insult, depending on the context. And when it comes to some of Facebook’s thornier problems, like trying to enforce consistent hate speech policies, human intervention may always be necessary.
Michael Kratsios, a deputy chief technology officer at the White House, said at the New Work Summit on Tuesday that regulators should get out of the way of advances in emerging technologies.
He cited progress toward a repeal of some regulations on commercial drones, such as rules prohibiting them from flying at night.
Unlike some experts who believe China is poised to dominate the A.I. age, Mr. Kratsios said he wasn’t worried about overseas competition. The United States, he said, has a “30-year head start” in A.I. development.
Marc Benioff, the chief executive of Salesforce, blasted companies like Facebook on Tuesday for addicting children to their products and renewed his calls for more government regulation of the tech industry.
Mr. Benioff compared a new Facebook Messenger product for children to candy cigarettes, which he used to pretend to smoke as a boy.
Silicon Valley is nearing the point where moral lines will have to be drawn by the government since the industry is not regulating itself and does not seem to be guided by a “strong hand of ethics,” he said.
There is a “crisis of trust,” he added, that will become a “tidal wave” among American consumers who are growing wary of tech giants.
One of the solutions he suggested was to move decision-making away from algorithms and back toward humans. He cited Facebook’s decision to disband its trending news curation team as an example.
“Facebook had a team promoting, sorting and focusing stories, 100 curators that they removed and put an algorithm in their place, and that started the downward spiral that they’re in today,” Mr. Benioff said.
He also spoke about the recent ban on kegs of beer at Salesforce offices after he recently stumbled across one while visiting a company he had acquired.
Should A.I. be more ‘human’?
Fei-Fei Li, a chief scientist at Google and a Stanford professor, has called on technologists to take a more “human centered” approach to the creation of artificial intelligence. On Tuesday at the New Work Summit, Ms. Li said that researchers must work to ensure that A.I. embodied human qualities and that it would ultimately operate alongside humans, not replace them.
At Stanford, Ms. Li was instrumental in the recent rise of “computer vision” systems that can recognize people and objects entirely on their own. At Google, she is working to package and sell these and other systems as cloud computing services, delivering the latest A.I. technology to a wide range of businesses.
But she said that as Google and other internet giants pushed these techniques forward, academia and the government must help ensure that A.I. evolved into something that enhanced our humanity, created as many jobs as it replaced and operated in safe and predictable ways.
In particular, Ms. Li said, academic institutions can help ensure that computer scientists work alongside social scientists in building this new breed of technology.
“A.I. has outgrown its origin in computer science,” she said.
Ultimately, said Ms. Li, who was born in China, A.I. reflects the people who build it more than other technologies do. For that reason and others, she said, A.I. researchers must work in a way that spans not only many industries but many cultures as well.
Tuesday’s first speaker at the New Work Summit was Kai-Fu Lee, who used to lead Google in China and knows a thing or two about American tech giants in China. His prognosis about whether companies like Facebook will ever be able to crack the world’s largest internet market?
“The American products are simply uncompetitive in the China market,” said Mr. Lee, who is now chief executive of Sinovation Ventures, a venture capital firm focused on Chinese technology. Even if internet titans from the United States could operate in China, he said, the local competition means they would have a hard time thriving.
“Messenger is a much worse product than WeChat,” he said, referring to Facebook’s messaging app and Tencent’s ubiquitous app for chatting, social networking, making payments and other tasks.
Mr. Lee sees other issues that augur against a big Facebook or Google renaissance in China. Multinational companies tend not to hire local managers to lead their China operations. “They’re not concerned about winning in the local market,” he said.
Trump administration silent on A.I.
Last year, the Chinese government unveiled a plan to become the world leader in artificial intelligence by 2030, vowing to create a domestic industry worth $150 billion. This manifesto read like a challenge to the United States, and in many ways it echoed policies laid down by the Obama administration in 2016.
John Krafcik, chief executive of the self-driving car company Waymo, took the stage at the New Work Summit on Monday night and spoke out for the first time since his company reached a settlement last week with Uber in a lawsuit over trade secrets that riveted Silicon Valley.
Waymo and Uber spent only four days at trial last week before settling, with Uber agreeing to provide Waymo 0.34 percent of its stock, worth about $245 million. The dispute between the companies started in 2016 when Uber bought Otto, a start-up founded by Anthony Levandowski, an early member of Google’s self-driving car program. Waymo, which was spun out of Google, accused Mr. Levandowski of stealing technology before leaving and accused Uber of using the misappropriated knowledge.
“This was a really special case with a really special set of circumstances,” Mr. Krafcik said. “For us, this was always about, and really just about, the fact that we needed to ensure Uber wasn’t using our trade secrets.” He added that he did not foresee Waymo suing other former employees.
Mr. Krafcik also discussed how Waymo was looking to start a ride-hailing service, which it is testing in Phoenix with thousands of driverless Pacifica minivans.
Jeff Wilke, Amazon’s chief executive of its consumer business, which includes its e-commerce operations, doesn’t often make public appearances. But on Monday night, he joined the New Work Summit to discuss the internet retailer’s move into artificial intelligence.
His key message: A.I. is everywhere, but that doesn’t mean it will take our jobs.
“If you look at the evolution of technology over the course of decades, tech doesn’t eliminate work; it changes work,” Mr. Wilke said.
He said that over the last five years, since Amazon bought a robot maker called Kiva Systems, it had built 100,000 of the robots — and also hired 300,000 people. “We still need human judgment,” he said.
Amazon has also embedded A.I. throughout the company, he added, with technologists working together with people who run businesses. The company is using machine learning and deep learnings, which are different flavors of A.I., to upgrade internal algorithms, he said.
As A.I. technology barrels ahead in Silicon Valley, it’s also starting to pick up steam as a political issue in Washington.
Over the weekend, I wrote about Andrew Yang, a former tech executive who has decided to run for president in 2020 as a Democrat on a “beware the robots” platform. He thinks that with innovations like self-driving cars and grocery stores without cashiers just around the corner, we’re about to move into a frightening new era of mass unemployment and social unrest.
So he’s proposing a universal basic income plan called the “Freedom Dividend,” which would give every American adult $1,000 a month to guarantee them a minimum standard of living while they retrain themselves for new kinds of work.
In modern artificial intelligence, data rules. A.I. software is only as smart as the data used to train it, as Steve Lohr recently wrote, and that means that some of the biases in the real world can seep into A.I.
If there are many more white men than black women in the system, for example, it will be worse at identifying the black women. That appears to be the case with some popular commercial facial recognition software.
