Reddit, the online internet forum, has started to implement a new policy to ban content that glorifies and incites violence, and among the first to go were forums for Nazi, racist and white supremacist groups.
The company outlined the update to its policy on Wednesday, with one statement in its help center and another by an administrator on the site itself, where a vocal community challenged the changes.
Reddit said it was taking the steps to clarify the way it has moderated posts in the past, and to bring its policy on allowable content in line with its values. “In particular, we found that the policy regarding ‘inciting’ violence was too vague,” the statement said.
Going forward, we will take action against any content that encourages, glorifies, incites, or calls for violence or physical harm against an individual or a group of people; likewise, we will also take action against content that glorifies or encourages the abuse of animals.
We understand that enforcing this policy may often require subjective judgment, so all of the usual caveats apply with regard to content that is newsworthy, artistic, educational, satirical, etc, as mentioned in the policy. Context is key.
Reddit said the updated policy would apply to memes, CSS/community styling, flair, subreddit names and usernames. If the content is “borderline,” it should be tagged with a warning.
“Even mild violence can be difficult for someone to explain to others if they open it unexpectedly,” the statement said.
But it added sometimes there were reasons to post violent content — such as with educational, newsworthy, artistic and satirical items — in which case context should be provided to show it was not gratuitous.
On Thursday, as news of the policy surged through the site, moderators began to question how it would be applied in Reddit’s micro-communities, or subreddits, where interests can range from hunting to Bible study, as well as in its dark corners, where people are urged to kill themselves or others.
Among the first to be banned were the subreddits r/NationalSocialism, r/Nazi and r/Far_Right.
In a statement on Thursday, Anna Soellner, a spokeswoman for Reddit, said the company was constantly assessing its content policy. “We strive to be a welcoming, open platform for all by trusting our users to maintain an environment that cultivates genuine conversation,” she said.
Reddit, which was founded in 2005 and proclaims itself “the front page of the internet” with 330 million monthly active users, had been resistant to outright bans on content. In 2014, Yishan Wong, who was then the company’s chief executive, wrote a blog post defending the company’s hands-off approach to the sometimes toxic content that appeared on the site.
A year later, under a new chief executive, Ellen Pao, the company announced that it would explicitly prohibit harassment against users. It said then that the move would promote free expression of its millions of users without fear of retribution from a vocal minority of them.
The crackdown comes as Reddit expands after receiving millions of dollars in financing in 2014 and again in 2017. It grew from 65 employees in 2015 to 260 employees this year, making it easier to execute new policies to enforce bans on toxic content.
The effectiveness of Reddit’s 2015 policy was analyzed in a study released last month of two subreddits that were banned — the racist r/CoonTown subreddit and r/fatpeoplehate, which mocked and abused overweight people.
The study suggested that the most effective tactic to fight hateful rhetoric might be to identify and shut down the spaces where hateful speech occurs, rather than targeting bad actors individually or in groups.