The group, an independent organization that advises the North Atlantic Treaty Organization, tested the tech companies’ ability to stop paid influence campaigns by turning to 11 Russian and five European companies that sell fake social media engagement. For 300 euros, or about $330, the researchers bought over 3,500 comments, 25,000 likes, 20,000 views and 5,000 followers, including on posts from prominent politicians like Ms. Vestager and Ms. Jourova.
After four weeks, about 80 percent of the fake clicks remained, the researchers said. And virtually all of the accounts that had been used to generate the clicks remained active three weeks after researchers reported them to the companies.
Researchers inflated the “likes” on a Facebook post by Margrethe Vestager, Europe’s top antitrust enforcer.
The report spotlights the continuing challenges for Facebook, YouTube and Twitter as they try to combat online disinformation and other forms of online manipulation. After Russia interfered in the United States’ 2016 presidential election, the companies made numerous changes to reduce the spread of online disinformation and foreign interference. In recent months, the platforms have announced takedowns of accounts in China, Saudi Arabia and, most recently, Africa, where Russia was testing new tactics.
But the report also brings renewed attention to an often overlooked vulnerability for internet platforms: companies that sell clicks, likes and comments on social media networks. Many of the companies are in Russia, according to the researchers. Because the social networks’ software ranks posts in part by the amount of engagement they generate, the paid activity can lead to more prominent positions.
The researchers bought engagements on about a hundred posts on Facebook, Instagram, Twitter and YouTube. They saw “little to no resistance,” Mr. Bay said.
After their purchase, the researchers identified nearly 20,000 accounts that were used to manipulate the social media platforms, and reported a sample of them to the internet companies. Three weeks later, more than 95 percent of the reported accounts were still active online.
The researchers directed most of the clicks to posts on social media accounts they had made for the experiment. But they also tested some verified accounts, like Ms. Vestager’s, to see if they were better protected. They were not, the researchers said.
The researchers found YouTube the worst at removing inauthentic accounts and the most expensive to manipulate. The researchers reported 100 accounts used for manipulation in their test to each of the social media companies, and YouTube was the only one that did not suspend any and provided no explanation.
Facebook, the world’s largest social network, was best at blocking the creation of accounts under false pretenses, but it rarely took content down. Instagram, which Facebook owns, was the easiest and cheapest to manipulate.
Ms. Bradshaw, who reviewed the report independently, said the reason accounts might have not been taken down was that “they could belong to real people, where individuals are paid a small amount of money for liking or sharing posts.” This strategy, she pointed out, makes it much harder for the platforms to take action.
