Turning Point: In July, the Federal Trade Commission announced that it would fine Facebook $5 billion, the largest penalty ever levied by the agency for consumer privacy violations.
A decade ago, Edward O. Wilson, the Harvard professor and renowned father of sociobiology, was asked whether humans would be able to solve the crises that would confront them over the next 100 years.
Since Mr. Wilson’s observation, technology’s godlike powers have increased dramatically, while the ancient, Paleolithic impulses of our brains have remained the same.
Yet this isn’t usually one of the complaints leveled against technology companies today — that the digital infrastructures of Facebook and Google have overwhelmed the natural capacities of our brains. Instead, we hear concerns that tech firms are collecting and tracking our personal data. Or that they’re simply too big.
Let’s imagine that we managed to solve the privacy issue. In this new utopia, we would own all our data, and tech giants would be forbidden from tracking our online whereabouts; they would have access only to the data we agreed to share.
While we might see fewer creepy ads and feel less paranoid about surveillance, the troubling trends connected to the online world would remain unaddressed.
Our addiction to social validation and bursts of “likes” would continue to destroy our attention spans. Our brains would still be drawn to outrage and angry tweets, replacing democratic debate with childlike he-said, she-said. Teenagers would remain vulnerable to online social pressure and cyberbullying, harming their mental health.
Yes, online privacy is a real problem that needs to be addressed. But even the best privacy laws are only as effective as our Paleolithic emotions are resistant to the seductions of technology.
A viral app called FaceApp recently persuaded 150 million people to hand over private images of their faces, paired with their names, simply by appealing to their vanity. How? The app offered the ability to create surreally accurate portraits of people as they would look many years in the future. Who owns the app (and the 150 million names and faces)? A Russian company based in St. Petersburg.
Who needs to hack elections or steal voter information when people will happily hand over scans of their faces when you appeal to their vanity?
With our Paleolithic instincts, we’re simply unable to resist technology’s gifts. But this doesn’t just compromise our privacy. It also compromises our ability to take collective action.
That’s because our Paleolithic brains aren’t built for omniscient awareness of the world’s suffering. Our online news feeds aggregate all of the world’s pain and cruelty, dragging our brains into a kind of learned helplessness. Technology that provides us with near-complete knowledge without a commensurate level of agency isn’t humane.
Our Paleolithic brains also aren’t wired for truth-seeking. Information that confirms our beliefs makes us feel good; information that challenges our beliefs doesn’t. Tech giants that give us more of what we click on are intrinsically divisive. Decades after splitting the atom, technology has split society into different ideological universes.
Simply put, technology has outmatched our brains, diminishing our capacity to address the world’s most pressing challenges. The advertising business model built on exploiting this mismatch has created the attention economy. In return, we get the “free” downgrading of humanity.
Here’s the good news: We are the only species self-aware enough to identify this mismatch between our brains and the technology we use. Which means we have the power to reverse these trends.
The question is whether we can rise to the challenge, whether we can look deep within ourselves and use that wisdom to create a new, radically more humane technology. “Know thyself,” the ancients exhorted. We must bring our godlike technology back into alignment with an honest understanding of our limits.
This may all sound pretty abstract, but there are concrete actions we can take.
First, policymakers can create a special tax for tech giants — a “downgrading tax” — that would make their business models, based on extracting and exhausting our attention spans, prohibitively expensive, while redistributing wealth to journalism, public education and the creation of new platforms that privilege human values and service to society.
Second, instead of joining free social media platforms that benefit from turning us into addicted, narcissistic extremists, we could agree to pay subscription fees to services that shun “likes” for features that empower our lives offscreen, making these services, in essence, fiduciaries acting in the best interests of humanity.
Third, instead of spreading disinformation, digital platforms could radically strengthen the media infrastructures that protect us from malicious viral content and tech-enabled distortions like “deepfakes” (fabricated videos manipulated by artificial intelligence to look genuine).
Candidates in the 2020 United States presidential election must educate themselves about the threat posed by technology’s race to outmatch our brains, and the news media must hold them accountable. No president can effectively deliver on his or her campaign promises without addressing the attention economy.
To create humane technology we need to think deeply about human nature, and that means more than just talking about privacy. This is a profound spiritual moment. We need to understand our natural strengths — our capacity for self-awareness and critical thinking, for reasoned debate and reflection — as well as our weaknesses and vulnerabilities, and the parts of ourselves that we’ve lost control over.
The only way to make peace with technology is to make peace with ourselves.