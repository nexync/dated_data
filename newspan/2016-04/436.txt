Things sometimes go wrong with airbags, food and drugs, prompting recalls. It can also happen with medical devices, though you’d think lifesaving devices like heart defibrillators or artificial hips would be closely monitored.
But the data needed to systematically and rapidly identify dangerous medical devices are not routinely collected in the United States.
It wouldn’t be that hard to do.
Problems with medical devices are not infrequent. Defibrillators implanted in nearly 200,000 patients were recalled in 2011 because of a faulty part. More recently, the Essure birth control device implanted in women’s fallopian tubes has been associated with pain and deaths. Improper handling of duodenoscopes — used by doctors to examine the small intestine — was linked to hundreds of cases of antibiotic-resistant infections in 2013 and 2014.
According to a report from the Brookings Institution, medical device problems that we know about contribute to about 3,000 deaths per year in the United States. There may be many more we do not know about because we do not track medical device use the way we track prescription drugs for quality and safety. Codes that uniquely identify prescribed drugs are routinely included in medical claims data — such as those made public by the Medicare program. These can be mined for signals of problems.
Reflecting this haphazard approach, a Senate report released this year accused Olympus, a Japanese manufacturer of contaminated duodenoscopes, of delayed reporting of known problems and chided the F.D.A. for its lethargic investigation of them. The report also found that none of the hospitals where problems surfaced properly documented them. Experts convened by the F.D.A. excoriated the manufacturer of the Essure birth control device for not collecting data that could have detected its risks.
The solution seems simple: Do for devices what we do for drugs. The F.D.A. has established the Sentinel Initiative to mine medical data to confirm or clear suspected problematic drugs. For example, one inquiry confirmed reports of intestinal problems associated with an antihypertensive drug. Another investigated whether a new anticoagulant drug was associated with a higher risk of bleeding than others.
Other nations have detected issues with such monitoring systems before American doctors and patients were probably aware of them. For instance, systems in Australia and England and Wales led to the discovery of problems with metal-on-metal artificial hip joints, before the F.D.A. called for a review of them and they were recalled in the United States. A Swedish system associated early drug-coated stents with increased risk of death compared with conventional bare-metal stents.
High-risk medical devices already include unique identifiers and bar codes similar to those on drug packaging and suitable for tracking. In the coming years, other devices will include them as well. Some members of Congress favor including device identifiers in medical claims, and F.D.A. Commissioner Robert Califf supports the approach. Peter Orszag, the former director of the Office of Management and Budget, reported in a Bloomberg View column last year that many medical societies, insurers and health care providers support it as well.
Not everyone agrees. The American Hospital Association and Marilyn Tavenner, while she was administrator for the Centers for Medicare and Medicaid Services, expressed concerns, citing higher costs.
The price tag for a medical device surveillance system that relies on such data is about $50 million a year. This does not include the one-time costs hospitals would have to pay to adapt to the system. Even at a multiple of the price, however, if it saved only a few tens of lives — and chances are it would save many more than that — it would be considered cost-effective. The defective defibrillators cost Medicare an estimated $287 million. The Inspector General of the Department of Health and Human Services, Daniel Levinson, says that faulty medical devices have cost taxpayers billions of dollars.
A significant limitation of medical surveillance systems is that their findings rely on correlations that may not be indicative of causation. However, as I and Steven Pizer, a Northeastern University health economist, noted in the American Journal of Managed Care, the point of such surveillance is to use a large amount of data to detect problems missed by more rigorous, but necessarily smaller, randomized trials. Statistical techniques can increase confidence that correlations from surveillance systems imply a causal relationship (when they really do) or cast doubt (when they don’t).
Medical devices are intended to cure, but some may cause harm. We’re not collecting the data that would help us know the difference.