Crisis Text Line is upending the suicide hotline, modernizing it for today’s teenagers, one text at a time.
Right now, algorithms are scouring vast data sets to determine the news you’ll be exposed to today on social media, the advertisements that will appear alongside your search results and what you’ll end up being charged for your next car ride. But can algorithms be used to address more urgent social and individual problems, like how to build trust or provide effective care? Can algorithms be used to increase the love and kindness in the world?
In this column two years ago, I reported on the Crisis Text Line and explained how it vets, trains, coaches and supervises volunteers scattered across the country, enabling them to provide high-quality counseling over a digital platform. At that time, the service had 600 counselors who had exchanged eight million messages with people seeking assistance. Today, it has over 3,700 counselors who have exchanged 56 million messages. And that number is expected to double within a year.
Crisis Text Line concludes every conversation with an automatic message asking users if they found the conversation helpful. Over all, 86 percent respond yes; that’s up from 76 percent four years ago, reflecting improvements in the organization’s training and supervision. Twenty percent of users also complete a post-conversation survey, providing additional information about themselves and their experience. Recently the organization hired Shairi Turner-Davis, a physician with experience in trauma, to serve as its chief medical officer. “My job is making sure that counselors don’t get burned out and ensuring that we’re keeping them up to speed on the latest in the fields of trauma, social work and crisis intervention,” she said.
These are successful outcomes, but a person who is depressed, has an eating disorder, is engaged in self-harm, or is in despair because of bullying or academic pressures often needs longer-term support. Crisis counseling isn’t meant to be therapy. “The job of a crisis counselor is to help move someone in pain from a hot moment to a cool calm,” Lublin says. Counselors will often offer connections to local services for follow-up help. In the 1 percent of cases in which counselors and supervisors believe a texter is at serious risk for suicide, the service initiates what is called an “active rescue,” calling the local police or 911.
What those 56 million text messages add up to is an extraordinary opportunity to save lives. The data can help identify when and where problems are spiking, and what interventions are warranted. For example, although National Suicide Prevention Awareness Month is observed in September, data show that suicidal ideation peaks in April and May — critical information for mental health counselors in schools and universities. Suicidal ideation is also triggered by popular culture aimed at youth.
The data can be used to flag issues that require greater attention. For example, one in five conversations from users under the age of 13 mention self-harm, usually cutting. In 40 percent of those conversations, the words “scared” and “alone” show up. After counseling, 62 percent of those texters report feeling less alone or more hopeful. These sentiments have a direct implication for counselors, said Bob Filbin, the organization’s chief data scientist. “These texters want to be heard,” he said.
Some of the insights from the data raise questions about prevailing assumptions in crisis counseling. One is the belief that counseling must be tailored by issue. “There’s this idea that a person experiencing a particular crisis needs a particular type of care,” Filbin said. “So if it’s sexual abuse or L.G.B.T.Q. or suicidal ideation, the care or the training would need to be different in each case.” But when Filbin examined the data, he found that not to be the case.
“One thing we know is that successful talk therapists adapt their therapy to the patient,” said Tim Althoff, a doctoral candidate in computer science at Stanford who collaborated with Mr. Leskovec and another colleague, Kevin Clark, on a paper published last year that applied large-scale computational linguistics to millions of conversations from the Crisis Text Line.
