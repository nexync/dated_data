The architecture of the internet has tremendous influence over what is made, and what is seen; algorithms influence what content spreads further on Facebook and turns up on top of Google searches. YouTube’s process for mechanically pulling ads from videos is particularly concerning, because it takes aim at whole topics of conversation that could be perceived as potentially offensive to advertisers, and because it so often misfires. It risks suppressing political commentary and jokes. It puts the wild, independent internet in danger of becoming more boring than TV.
Instead, he’s subject to the whims of the algorithm. To rein in its sprawling video empire — 400 hours of video are uploaded to the platform every minute — YouTube uses machine learning systems that can’t always discern context, or distinguish commentary or humor from hate speech. That limitation means that YouTube routinely pulls ads from content deemed “not advertiser-friendly.” That includes depictions of violence or drug use, “sexual humor” and “controversial or sensitive subjects,” including war and natural disasters. YouTube has previously blocked ads on Mr. Pakman’s news videos referring to ISIS church bombings and the assassination of a Russian diplomat. YouTube creators can appeal the decision to a human who will watch the video, but the recent changes have upended the usual processes, often leaving creators without an official channel for appeal.
This is not all the algorithm’s fault. People create these systems, and they are sensitive to bad press and skittish advertisers. The YouTube ad crisis — and the company’s response — also speaks to a persistent public misunderstanding of the worth of digital creators. The mainstream media barely engages with YouTube videos as an artistic product in the way it does traditional television and film. Coverage is focused on how much money YouTube stars make, how improbably famous they are among teenagers and, now, on the small number of racist and extremist videos that have slipped through the cracks of the ad system.
Jamie Byrne, director of creators and enterprise at YouTube, said that concerned companies had requested tougher controls to keep their ad dollars flowing. “For creators to flourish on our platform, we need an incredibly strong advertising community engaged on YouTube as well,” he said. He hopes that as the ad systems learn to decipher context, and advertisers relax, creators will see greater returns.
Media power has consolidated in the past several decades, with a smaller crew of billionaires controlling journalism and entertainment. The internet was supposed to offer an opportunity for a diverse group of upstarts to challenge the corporate structure. But the same consolidation of power has happened online. Independent blogs have been shut down or snapped up by bigger companies. YouTube has long been owned by Google, which has gobbled up a greater share of online ad revenue in recent years. Google and Facebook are now so dominant that they form a practical duopoly over digital advertising. Meanwhile, YouTube is making a run at Netflix with its original-content subscription service, YouTube Red, and going after television with YouTube TV, which allows subscribers to stream TV channels online for $35 a month.
All of that means that new media creators hoping to make a living online need to play by YouTube’s rules, and steer clear of anything “potentially objectionable” — not to real people, who might actually be offended, but to robots. If YouTube wants to fulfill its promise of an online environment where independent creators can make interesting work, it will find a way to scrub ads from truly vile content without penalizing the merely controversial.