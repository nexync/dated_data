The company previously relied on its users and a network of trusted monitors to report inappropriate material, which was then prioritized by an algorithm before being subjected to human review.
The new technology applies “machine learning” to identify and prioritize extremist videos for review. While most still undergo a human review before being removed, a YouTube spokeswoman said the technology might automatically remove videos and issue warnings to the content’s creators.
The system was designed to identify videos posted by extremists groups, especially the Islamic State and its sympathizers, but any content from Syria and conflict zones where extremists operate risks being caught in YouTube’s net.
Organizations that use such videos in their research regularly download copies and share them among themselves, but journalists and smaller groups do not have the same technical resources and therefore rely on YouTube to host the videos.
One group that monitors these videos is the International, Impartial and Independent Mechanism, a legal team established by the United Nations to collect and preserve evidence of crimes for use by courts and international tribunals.
More than 6,000 videos documenting the Syrian conflict since 2014 were temporarily removed when YouTube shuttered the channel of the Qasioun News Agency, an activist media group with dozens of correspondents in Syria.
Airwars also had around a dozen of its videos temporarily removed, and at least five other channels belonging to Syrian opposition groups and the Syrian Ministry of Defense were deleted.
YouTube’s community guidelines stipulate that a channel can be removed for three violations of the platform’s guidelines in a three-month period. The speed at which the new system is analyzing and issuing warnings on previously posted videos appears to be one reason some channels are being taken down without advance notice.
“From a warning to a channel being shut down happens in a short journey,” Mr. Woods said.
While the new system appears to be correctly identifying graphic content like execution videos and Islamic State propaganda, it is mislabeling some videos. Three of the Airwars videos removed from its YouTube channel were aerial videos of airstrikes released by the Pentagon showing no graphic content.
Mr. Kharrat of the Qasioun News Agency said one of its videos had been cited for “spreading violence,” even though it simply documented clashes between Syrian government forces and opposition groups.
Eliot Higgins, a journalist who founded the investigative website Bellingcat, said he had received an email warning about a video he uploaded in 2013, and a second notice for an edited video of the Islamic State’s killing of the journalist James Foley that was not available publicly.
With 400 hours of video uploaded to YouTube every minute, a spokeswoman for the company said the new filtering technology was designed for scale and would improve with time. When it is brought to the site’s attention that a video or channel has been removed mistakenly, she said, YouTube acts quickly to reinstate it.
Organizations worried that their content might be taken down are advised to provide context about the events in the online summary and metadata tags, and to be explicit about their intent in publishing these videos.