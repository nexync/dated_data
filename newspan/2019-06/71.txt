Opinion|When a Politician Is Called a ‘Lousy Traitor,’ Should Facebook Censor It?
When a Politician Is Called a ‘Lousy Traitor,’ Should Facebook Censor It?
A case could give European courts enormous power to force the worldwide removal of defamatory statements.
Ms. Daskal and Dr. Klonick are law professors.
In April 2016, a Facebook user shared an article featuring a photo of the Austrian Green party’s leader at the time, Eva Glawischnig-Piesczek, along with added comments labeling her a “corrupt oaf,” a “lousy traitor” and “member of a fascist party.” The comments were apparently a protest of her support for refugees. Ms. Glawischnig-Piesczek claimed that she had been defamed and demanded that Facebook take down the post.
Facebook eventually did, but only once it was ordered to do so by an Austrian court — and in a way that made the post still viewable by users outside Austria. For Ms. Glawischnig-Piesczek, that wasn’t enough. She demanded that Facebook take down all photos of her accompanied by identical or “equivalent” commentary — commentary sending the same message in different words — and added, when the case was appealed to the Austrian Supreme Court, a demand that it do so for users outside Austria as well.
Now before the European Court of Justice, the case could empower governments to stamp out certain kinds of political speech by demanding that private platforms like Facebook do the dirty work of taking it down — for users not just in their own countries but everywhere.
Specifically, the European Court of Justice will decide whether European Union law allows a national court to order Facebook to remove posts deemed defamatory as well as identical or similar content — and if so, whether this order can apply to content posted and viewable by users in countries outside of the court’s jurisdiction.
There’s reason to be concerned. This month, a broad opinion from an advocate general — an adviser who considers submissions to the European Court of Justice and offers an independent legal opinion — foreshadows the kind of censorship that could ensue. Such input has significant influence on the court, which follows the advocate general’s opinion more often than not.
His opinion says that Facebook cannot be ordered to look for and take down posts that are “equivalent” to the original defamatory posts because identifying them would impose the kind of general monitoring obligation on Facebook that European Union law prohibits. But, he says, Facebook can be ordered to remove posts that are identical to the original defamatory posts. And he concludes that the relevant E.U. law does not speak to, and thus does not prevent courts that deem content defamatory in their own country from issuing orders that would make Facebook remove content posted by or appearing in the newsfeeds of users all across the world.
This opinion is misguided, in part because it’s much more difficult than it sounds to define, let alone reliably identify, an “identical” post. In the Austrian case, the user posted an article and photo with an apparent insult. But a different user might post the very same material not as a critique of Ms. Glawischnig-Piesczek but in an attempt to draw attention to her plight. For example, someone could share the post calling Ms. Glawischnig-Piesczek a “corrupt oaf” with the intent of highlighting what they saw as the cruelty of her critics. The content might be identical, the meanings could be entirely opposed. Such is the fundamentally contextual nature of speech.
As sophisticated as artificial intelligence is and is likely to become, it cannot reliably distinguish between defamation and its critique, or to distinguish between defamation and satire. The only way for a platform to effectively do so is to put human beings in the position of monitoring the content viewed and shared by users, and then engage in an in-depth analysis to assess meaning and intent.
Even if this were something that large tech companies like Facebook, Google and Twitter could do in a sufficiently nuanced way, what about the smaller companies that lack the necessary resources? The likely response would be the most cost-effective, risk-averse one: Just take down any post with the prohibited words — thereby removing legitimate discourse, satire and defamation alike. Discourse would, over time, become increasingly stilted and constrained.
Of equally grave concern, if the advocate general’s opinion is embraced by the European Court of Justice, providers and internet platforms like Facebook could be required to search for and remove content that’s deemed defamatory in one country even when it is posted by or simply appears in the newsfeeds of residents of other countries. It could be ordered to carry out takedowns globally, so that no one, anywhere in the world, could see material that the courts of a single country have deemed defamatory. This allows a single country to determine what is and is not permitted speech for everyone everywhere. The most censorship-prone country wins.
Encouragingly, the advocate general recommends that national courts use these global powers sparingly. Specifically, he counsels “self-limitation” by courts and suggests geoblocking as an alternative to global removal orders, particularly given the divergence of defamation law across the union.
But the opinion nonetheless leaves the possibility of global takedown orders on the table in both this and other cases. As he puts it, applicable law “does not preclude” a court ordering Facebook or other social media companies to engage in “worldwide” removal of information disseminated on their platforms.
If the court rules the Austrian court can issue global takedown orders to Facebook, courts in other union countries might follow.
The assault on speech would be a serious one. Of course, governments can and should, consistent with human rights obligations, be able to set their own rules. But when it comes to things like political speech — an area in which the definitions of what is and is not permitted vary greatly across borders — governments should do so only for their citizens and residents. And they should not turn private companies into censors in their quest to define the scope of civil discourse.
The court is expected to give a ruling this summer. If Ms. Glawischnig-Piesczek gets her way, Facebook will be put in the role of global censor on behalf of governments around the world.
Jennifer Daskal is an associate professor at American University Washington College of Law. Kate Klonick is an assistant professor at St. John’s University Law School.