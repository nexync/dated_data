Readers discuss issues of inaccuracy and human fallibility.
Mr. O’Neill should heed the warning about facial recognition from San Francisco, which recently prohibited its agencies from using the powerful but flawed technology.
There are numerous issues with its use, none of which are resolved by the N.Y.P.D.’s lack of transparency. For example, facial recognition is more likely to be inaccurate when used on images of people of color, disproportionately affecting our clients at the Legal Aid Society.
While facial recognition should be banned, at a minimum transparency is necessary. The public deserves more information from the N.Y.P.D. on this new tool and how it is used.
Thankfully, the Public Oversight of Surveillance Technology Act is pending in the New York City Council. The legislation would shine a light on this technology and the N.Y.P.D.’s other unchecked surveillance tools, like automated license plate readers. The Council cannot delay any longer and must pass the POST Act now.
The writer is a staff attorney in the Digital Forensics Unit at the Legal Aid Society.
I take Police Commissioner James O’Neill at his word that facial recognition technology makes New York City safer by enabling law enforcement to do its job more effectively. He outlines several ways that it has. But by focusing on its advanced capabilities, he misses the bigger target.
Humans, including police officers, are fallible, and that’s the concern that leaders like Commissioner O’Neill should help address. It’s often the users who fail to live up to technology’s promise.