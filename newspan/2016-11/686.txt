Something is deeply wrong when the pope’s voice, reputation and influence can be borrowed by a source that describes itself as “a fantasy news site” to claim that he has endorsed a presidential candidate, and then be amplified, unchallenged, through a million individual shares.
The attention paid to fake news since the election has focused largely on fabrications and outright lies, because they are indefensible, easy to identify and extraordinarily viral. Fake news is created by the kinds of people who, when asked, might call their work satire, or admit that they’re in it for the money or for the thrill of deception. Theirs is a behavior that can and should be shunned, and that Facebook is equipped, and maybe willing, to deal with.
For many people, and especially opponents of President-elect Donald J. Trump, the attention paid to fake news and its role in the election has provided a small relief, the discovery of the error that explains everything. But as the attention has spread widely — even President Obama talked passionately about it on Thursday — it may lead to an unwanted outcome for those who see it not just as an explanation, but also as a way to correct the course. It misunderstands a new media world in which every story, and source, is at risk of being discredited, not by argument but by sheer force.
False news stories posted on fly-by-night websites were prevalent in this election. So, too, were widely shared political videos — some styled as newscasts — containing outright falsehoods, newslike image memes posted by individuals and shared by millions, and endlessly shared quotes and video clips of the candidates themselves repeating falsehoods.
During the months I spent talking to partisan Facebook page operators for a magazine article this year, it became clear that while the ecosystem contained easily identifiable and intentional fabrication, it contained much, much more of something else.
I recall a conversation with a fact checker about how to describe a story, posted on a pro-Trump website and promoted on a pro-Trump Facebook page — and, incidentally, copied from another pro-Trump site by overseas contractors. It tried to cast suspicion on Khizr Khan, the father of a slain American soldier, who had spoken out against Donald J. Trump.
The overarching claims of the story were disingenuous and horrifying; the facts it included had been removed from all useful context and placed in a new, sinister one; its insinuating mention of “Muslim martyrs,” in proximity to mentions of Mr. Khan’s son, and its misleading and strategic mention of Shariah law, amounted to a repulsive smear. It was a story that appealed to bigoted ideas and that would clearly appeal to those who held them.
This tactic was used on the language of social justice, which was appropriated by opponents and redeployed nihilistically, in an open effort to sap its power while simultaneously taking advantage of what power it retained. Anti-racists were cast as the real racists. Progressives were cast as secretly regressive on their own terms. This was not a new tactic, but it was newly effective. It didn’t matter that its targets knew that it was a bad-faith maneuver, a clear bid for power rather than an attempt to engage or reason. The referees called foul, but nobody could hear them over the roar of the crowds. Or maybe they could, but realized that nobody could make them listen.
Facebook may try to address the narrow version of the problem, the clearly fabricated posts. Facebook has plenty of tools at its disposal and has already promised to use one, to bar sites that have been flagged as promoting falsified content from using its advertising platform. But the worst identified defenders make their money outside Facebook anyway.
Another narrow response from Facebook could be to assert editorial control over external forces. Facebook tried this, to a very limited extent, with Trending Topics. Members of the company’s editorial staff wrote descriptions of trending news stories, accompanied by links they deemed credible. This initiative collapsed in a frenzy of bias accusations and political fear. But it is easy to imagine a system in which a story, upon reaching some high threshold of shares, or a source, upon reaching some cumulative audience, could be audited and declared unreliable. This could resemble Facebook’s short-lived experiment to tag satire articles as such.
A number of narrow measures could stop a fake story about the pope, for example. But where would that leave the rest of the media? Answered and rebutted, and barely better positioned against everything else that remained. It would be a still-dominant news environment in which almost everything there before remained intact, the main difference being that it would have all been declared, implicitly, not fake.
Fake news operations are closely aligned with the experienced incentives of the Facebook economy — more closely, perhaps, than most of the organizations that are identifying them. Their removal will be an improvement. The outrage at their mere existence, and at their promotion on a platform with the stated goal of connecting the world, will have been justified.
But the outrage is at risk of being misdirected, and will be followed by the realization that the colloquial “fake news” — the newslike media, amateur and professional, for which truth is defined first in personal and political terms, and which must only meet the bar of not being obviously, inarguably, demonstrably false — will continue growing apace, gaining authority by sheer force, not despite Facebook but because of it. The company that created the system that resulted in hoax news stories should try to eliminate them, and with any luck it will. But the system stands to remain intact.
Media companies have spent years looking to Facebook, waiting for the company to present a solution to their mounting business concerns despite, or perhaps because of, its being credited with causing those concerns. Some have come to the realization that this was mistaken, even absurd. Those who expect the operator of the dominant media ecosystem of our time, in response to getting caught promoting lies, to suddenly return authority to the companies it has superseded are in for a similar surprise.