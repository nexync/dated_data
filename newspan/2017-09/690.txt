What does it take to advertise on Facebook to people who openly call themselves “Jew haters” and want to know “how to burn Jews”? About $10 and 15 minutes, according to what the investigative nonprofit ProPublica recently uncovered.
Some of Facebook’s users may find it even harder to accept what happened. How could the site that we use to keep in touch with friends and family, share baby pictures, and keep up with politics and volunteer work be made so easily to cater to the interests of Nazis?
But anyone who understands how Facebook works shouldn’t have been surprised. That’s because the same digital platform that offers us social interaction, news, entertainment and shopping all in one place makes its money by making it cheap and easy to send us commercial or political messages, often guided by algorithms. The recent scandal is just a reminder.
Almost every feature on Facebook is designed to make the site engaging — to encourage you to spend time there while Facebook serves more ads to you. At the same time, users can share “promoted posts” — targeted messages that advertisers pay Facebook to place in their feeds — merging pay-for-play content with the natural flow of information among friends and family. It’s a powerful combination.
People who use the platform to keep in touch with loved ones may forget that the site makes its money by serving as a conduit for whatever messages people with money want to push at us. You’ll rarely hear the company’s chief executive, Mark Zuckerberg, mention that when he offers lofty statements about how his company makes the world more open and connected and brings us closer together.
While it does help us communicate and stay in touch, it also does much more: Facebook has become the go-to site for anyone hoping to reach a big audience — whether to sell shoes or to sell politics, and it’s become profitable by doing so. That is because most of its systems are either largely or entirely automated. This lets the site scale up — it is up to two billion monthly users now — and keeps costs down.
Facebook also saves money through community policing, relying heavily on its users to do the legwork of flagging inappropriate content. Policies are enforced unevenly. For example, many people use Facebook pseudonyms, which violate the site’s “real names only” policy. But whether such users see their accounts suspended often depends on whether they’re reported by other users. This means those using pseudonyms to protect their identities while posting about human rights violations in repressive regimes and are flagged by members of those regimes may face consequences for breaking the rule, while others go unnoticed.
Human employees are expensive, and algorithms are cheap. Facebook directly employs only about 20,658 people — roughly one employee per 100,000 users. With so little human oversight and so much automation, public relations crisis like the one that surrounded the ads for hate groups are inevitable.
So why do billions of us still use Facebook? Because everyone else is already there. Economists call this a “network effect” — there are products that are hard to compete with once they capture an substantial audience. Facebook also uses its enormous cash pile to gobble up competitors or to copy their features, and has already hoarded giant amounts of data that provide it with ad-targeting advantages that would-be competitors cannot easily replicate. It’s a combination that leaves it without effective competition.
This, combined with deep surveillance-based profiling, enormous scale, automation, lack of sufficient human oversight and a tendency to react to public relations crises instead of making proactive changes helps to explain why, during the 2016 presidential race, the site was swamped with misinformation and outright fraudulent fake news, with actors ranging from foreign troublemakers to make-a-buck hucksters to ideologically motivated political groups.
Here’s the hard truth: All these problems are structural. Facebook is approaching half-a-trillion dollars in market capitalization because the business model — ad-targeting through deep surveillance, emaciated work force, automation and the use of algorithms to find and highlight content that entice people to stay on the site or click on ads or share pay-for-play messages — works.
The trouble is Facebook’s business model is structurally identical whether advertisers are selling shoes, politics or fake diet pills, and whether they’re going after new moms, dog lovers or neo-Nazis. The algorithms don’t know the difference, and Facebook’s customers are not its users.
Rather, as this latest incident should remind us, we are Facebook’s product. Our attention and eyeballs are sold to the highest bidders, whatever they may be peddling.