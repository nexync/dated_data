For a sense of the dilemma confronting Facebook over its ad-targeting system, consider the following word: confederate.
As of Wednesday, any prospective advertiser who typed that word into Facebook’s ad-targeting engine would be prompted to distribute their ad to a potential audience of more than four million users who had indicated an interest in the Confederate States of America, according to a test by The New York Times.
There are plenty of Civil War buffs, of course, as well as students and scholars who have taken an academic interest in the Confederacy. Yet Facebook must also be mindful in today’s charged political atmosphere that some might use its targeting system to reach those who support the Confederacy as part of a white nationalist worldview.
It illustrates the blurry lines and policing challenge that confront Facebook in its ad targeting. And after a year in which the social network has accepted more responsibility to crack down on false or offensive material, and last week, when the company twice announced new measures to prevent abuses by advertisers, some experts said the scale of that challenge is only starting to become apparent.
“What we’re actually talking about is all of the social issues one can think of — any social issue, social debate, social strife — being reproduced in this arena,” said Sarah T. Roberts, an assistant professor at the University of California, Los Angeles, who studies content moderation on digital platforms.
Facebook said it had multiple safeguards to ensure that an ad campaign was appropriate. While its system is far from perfect — the company recently disclosed that it allowed Russian operatives using fake accounts and pages to place ads on topics that polarized American voters, like race and immigration — the company said it would block an ad that included overtly racist content or directed users to a web page promoting racist ideas.
“We are taking a hard look at our ads policies and enforcement, and are looking at ways we can do better,” Mr. Goldman said.
How do people end up in the potential audience for Facebook’s ad-targeting categories in the first place? Facebook creates an ad category corresponding to a subject through a mix of human discretion and automated processes that it declined to describe.
Facebook users then effectively sort themselves into the targeting category by liking and visiting certain pages on the social network and through other activities they engage in on the service. Facebook has said that liking a page is one signal among many that helps it place users into the categories that advertisers can target.
So if Facebook creates, say, a red wine category, people increase their likelihood of being included in it by engaging with Facebook pages dedicated to the topic.
Once an ad category exists on Facebook, advertisers can push their messages to those users. Those who may be targeted in an ad campaign around the Confederate States may be Civil War buffs who visited or liked a page about the Confederacy set up by a seller of history books.
But advertisers can also gain access to people associated with Facebook pages that perpetuate false, misleading or divisive information. For example, many people who liked two pages on Facebook that frequently defend the Confederacy are likely to be included in the Confederate States of America category that advertisers can target.
Stephanie McCurry, a Civil War historian at Columbia University, examined both pages and found them littered with “fake history,” such as the suggestion that slavery was not the central reason for secession.
Despite their potential to offend, Facebook’s Confederacy pages do not appear to run afoul of the company’s standards on issues like hate speech. Some veterans of the digital advertising business said that as long as that is the case, it should be up to advertisers to determine whether to target categories composed partly of people who like these pages.
But Ms. Roberts at U.C.L.A. argued that simply by allowing Confederate States of America and similar pages to exist and then using this content to help advertisers target people with those interests, Facebook was blessing the views expressed there as legitimate.
Other Facebook ad-targeting categories that fall into the gray area of being legitimate in principle but potentially problematic or open to misuse include Wehrmacht, which refers to the Nazi-era German military, and Benito Mussolini, the Fascist Italian leader during World War II, according to a test of Facebook’s ad-targeting system by The Times.
Advertisers who target an ad using the term Wehrmacht would probably gain access to many people who liked a page dedicated to the Wehrmacht that appears to celebrate the Nazi-era military.
He said people who esteem the Wehrmacht can only do so while “ignoring the fact that they were massacring supposedly inferior racial groups in the Eastern campaign,” though he defended their right to pursue an interest in the Wehrmacht’s tactics and equipment.
Scott Galloway, a marketing professor at New York University and author of a forthcoming book on the big tech companies, said Facebook should not necessarily ban content that celebrates institutions like the Confederacy or the Wehrmacht and advertising that targets people interested in these subjects. But he said allowing this content and selling ads around it should reflect on Facebook the same way it would reflect on, say, CNN or The Washington Post.
