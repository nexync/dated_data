A district in New York has adopted the technology in the name of safety. Opponents cite privacy and bias concerns.
LOCKPORT, N.Y. — Jim Shultz tried everything he could think of to stop facial recognition technology from entering the public schools in Lockport, a small city 20 miles east of Niagara Falls. He posted about the issue in a Facebook group called Lockportians. He wrote an Op-Ed in The New York Times. He filed a petition with the superintendent of the district, where his daughter is in high school.
The decision underscores how facial recognition is spreading across the country and being deployed in new ways in the United States, as public officials turn to the technology in the name of public safety.
A few cities, like San Francisco and Somerville, Mass., have barred their governments from using the technology, but they are exceptions. More than 600 law enforcement agencies started using the technology of one company, Clearview AI, in just the past year. Airports and other public venues, like Madison Square Garden in Manhattan, have adopted it as well.
Schools are a newer front, and the debate that took place in Lockport encapsulates the furor surrounding the technology. Proponents call it a crucial crime-fighting tool, to help prevent mass shootings and stop sexual predators. Robert LiPuma, the Lockport City School District’s director of technology, said he believed that if the technology had been in place at Marjory Stoneman Douglas High School in Parkland, Fla., the deadly 2018 attack there may never have happened.
But opponents like Mr. Shultz say the concerns about facial recognition — namely privacy, accuracy and racial bias — are even more worrisome when it comes to children.
The debate in Lockport has unfolded over nearly two years. The school district initially announced its plans to install a facial recognition security system, called Aegis, in March 2018. The district spent $1.4 million, with money it had been awarded by the state, to install the technology across 300 cameras.
But when administrators wanted to do a test run last May, the State Education Department told them to hold off, partly in response to mounting public concerns over student privacy. The state wanted Lockport to make sure that students’ data would be properly protected, and demanded a policy that would forbid the use of student data, including their photos.
By June, Lockport officials said they had adjusted their policies, and they began testing parts of the system. In late November, the State Education Department said the district’s revised policy addressed its concerns. In January, the school board unanimously approved the latest policy revision.
When the system is on, Mr. LiPuma said, the software looks at the faces captured by the hundreds of cameras and calculates whether those faces match a “persons of interest” list made by school administrators.
That list includes sex offenders in the area, people prohibited from seeing students by restraining orders, former employees who are barred from visiting the schools and others deemed “credible threats” by law enforcement.
If the software detects a person on the list, the Aegis system sends an alert to one of 14 rotating part- and full-time security personnel hired by Lockport, Mr. LiPuma said. The human monitor then looks at a picture of the person in the database to “confirm” or “reject” a match with the person on the camera.
The technology will also scan for guns. The chief of the Lockport Police Department, Steven Abbott, said that if a human monitor confirmed a gun that Aegis had detected, an alert would automatically go to both administrators and the Police Department.
Days after the district announced that the technology had been turned on, some students said they had been told very little about how it worked.
Critics of the technology, including Mr. Shultz and the New York Civil Liberties Union, point to the growing evidence of racial bias in facial recognition systems. In December, the federal government released a study, one of the largest of its kind, that found that most commercial facial recognition systems exhibited bias, falsely identifying African-American and Asian faces 10 to 100 times more than Caucasian faces. Another federal study found a higher rate of mistaken matches among children.
In Lockport, black students are disproportionately disciplined. In the 2015-16 school year, 25 percent of suspended students in the district were black even though enrollment was only 12 percent black, according to data from the federal Department of Education.
Mr. LiPuma, the director of technology, said he believed that Lockport’s system was accurate. He also said he, as well as some other school officials, would like to add suspended students to the watch list in the future, despite the State Education Department’s recent directive that Lockport make it clear in its policy that it is “never” to use the system “to create or maintain student data.” Most school shootings in the last decade, Mr. LiPuma said, were carried out by students.
Jason Nance, a law professor at the University of Florida who focuses on education law and policy, warned that listing students as “persons of interest” could have unintended consequences.
“If suspended students are put on the watch list, they are going to be scrutinized more heavily,” he said, which could lead to a higher likelihood that they could enter into the criminal justice system.
Jayde McDonald, a political science major at Buffalo State College, grew up as one of the few black students in Lockport public schools. She said she thought it was too risky for the school to install a facial recognition system that could automatically call the police.
“Since the percentages for the false matches are so high, this can lead to very dangerous and completely avoidable situations,” Ms. McDonald said.
She added that she believed police officers would “do whatever it takes in order to stop a suspicious person,” even if that person was a young student in school.
Opponents of the new technology now pin their hopes on state lawmakers. In April, Assemblywoman Monica Wallace, a Democrat from Lancaster, introduced a bill that would force Lockport to halt the use of facial recognition for a year while the State Education Department studied the technology. The bill easily passed in the Assembly but was not taken up by the Senate.
Ms. Wallace said she intended to make passing the bill a priority in this new legislative session.
She said school districts could, for instance, take smaller steps like upgrading entrances and exits, hiring school resource officers, and investing in counselors and social workers.
Mr. Shultz said he would keep making his case.
