It is for this reason that on Jan. 9 we filed a federal civil lawsuit in the Southern District of New York against Twitter for providing support and resources to the Islamic State, leading to the murders of Nohemi, Alexander and Sascha.
In the aftermath of Sept. 11, 2001, Congress passed antiterrorism legislation prohibiting any entity or person connected with the United States from providing “material support or resources” to designated foreign terrorist organizations. Typically we think of such entities as those that supply funds, launder money or refine oil, but the law should also apply to entities that provide services, resources and platforms for communications, including Twitter.
This is not a decision we made lightly. We are Twitter users. It is one of the most effective platforms to communicate a message instantly, globally and with immediate impact.
But it is also one of the platforms most preferred by the Islamic State.
The Islamic State, also known as ISIS, and its supporters have used Twitter for recruiting, planning, issuing threats and taking credit for their attacks. Simply put, the Islamic State uses Twitter as a tool of terrorism. It should be denied access to this weapon.
Government officials have criticized Twitter for allowing terrorists to access the platform. Congressman Ted Poe, chairman of the House Foreign Affairs Subcommittee on Terrorism, nonproliferation and trade, complained in August 2012 about Twitter’s not shutting down terrorist accounts and argued that terrorists using Twitter “is a violation of U.S. law.” In September of that year, Mr. Poe and several other members of Congress wrote to the F.B.I. director asking that he demand that Twitter block accounts of various terrorist groups.
In a February 2016 statement, Twitter acknowledged that the terrorist threat was changing and said it was adapting to the changes. The company announced that it had suspended more than 125,000 accounts since mid-2015 “for threatening or promoting terrorist acts” and enlarged the teams that review reports related to terrorism. When pertinent, Twitter also says it cooperates with law-enforcement agencies and works with organizations to combat extremist content online. In August, Twitter said it suspended an additional 235,000 accounts associated with terrorism.
But we believe that Twitter doesn’t do enough to proactively monitor, identify and remove terrorist-related accounts and hasn’t made an effective or prolonged effort to ensure that the accounts are not re-established. In short, Twitter’s actions are too little, too late.
Hany Farid, the chairman of the computer science department at Dartmouth College and senior adviser at the Counter Extremism Project, has suggested one way Twitter could do more. He has developed software that can block terror-related posts on the internet. It could be used to create a database of known extremist content and prevent future uploads of the material on social media.
We both used social media platforms, including Twitter, to frantically search for our loved ones in the hours following the attacks. We know that our lawsuit will not diminish the power of social media platforms, but if our taking a stand diminishes the ability of the Islamic State and its demonic brethren to carry out future murderous campaigns, then perhaps we will have spared others the fate of Nohemi, Alexander and Sascha.