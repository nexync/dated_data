Book Review|Justice Is Blind. Sometimes, So Is Prejudice.
Justice Is Blind. Sometimes, So Is Prejudice.
Last winter a cellphone video of an encounter between a white plainclothes Boston police officer and a young black man made the rounds on social media. The man, identified by The Boston Globe as Keith Antonio, was on his way to a barbershop when he spotted a police car. Thinking he was about to be stopped, he hit record.
The officer, Zachary Crossen — beefy, with an expressive frown and a knitted gray and gold Boston Bruins hat — called to Antonio from the passenger seat, his window rolled down. “You’re not Kevin, by any chance, are you?” he asked.
“Of course,” Antonio said.
“What is your name?” Officer Crossen asked.
“Why do you want to know my name?” came the reply.
Things went downhill. Crossen and his partner got out of their car. Antonio apparently flipped them off. He began calling Crossen names. The officer pulled out his own cellphone to record and asked Antonio patronizing questions about whether he had a job.
No one ended up getting hurt, and Antonio, who hadn’t committed a crime, wasn’t arrested. But activists seized on the exchange. It was evidence, they said, of the hostile treatment African-Americans continue to receive from the police, even in cities like Boston, known for progressive values. Would a young white man have been accosted in the same way?
Jennifer L. Eberhardt, a psychologist at Stanford, doesn’t address the incident in “Biased,” her unexpectedly poignant overview of the research on cognitive biases and stereotypes, especially racial bias in criminal justice. But it’s no stretch to think that she would see bias at play.
The biases that most interest Eberhardt aren’t overtly racist beliefs. She doesn’t doubt that white supremacists are still among us (and she devotes a chapter to the white nationalist rally in Charlottesville, Va., in 2017). But in light of the fact that public opinion surveys show a decline in racist attitudes over the past few decades, while the unequal treatment of people of color stubbornly persists, Eberhardt focuses on a more likely culprit: unconscious prejudice.
As Eberhardt describes it, the human brain is a categorization machine. Our cognitive systems continuously sort the elements of our perception into categories and subcategories so that we can function effectively in the world. That thing walking up to us now? It’s a dog, medium-size, with a wagging tail. We use our prior experience with and cultural knowledge of categories to form expectations about what’s going to happen next. Those expectations influence our behavior. If our brains didn’t apply categorical knowledge, usually before we’ve had a chance to consciously reflect, we’d experience everything as if for the first time. We’d be flummoxed by the simplest task.
The problem is that when we live in a society divided by race, gender, class or some other category, our brains learn those social groupings, too, and apply them to order our perceptual field, even when they are more arbitrary than real, even when the “knowledge” attached is a pernicious stereotype and even if we’re committed to equality. This is implicit bias.
Eberhardt gives striking examples from her research of how racial categories and stereotypes affect perception. In one study, she and her colleagues found that people’s brains were more active when they were looking at a face from someone of their own racial group. This, Eberhardt says, helps to explain why people sometimes do poorly at recognizing individuals from other groups — a finding that matters for criminal justice, where mistaken identification is common.
In another study, Eberhardt examined the stereotype linking black men and crime. Police officers were asked to look at a computer screen. Half were exposed subliminally to crime-related words like “apprehend” and “capture”; these blinked for a fraction of a second. The other half was exposed to gibberish. The officers then saw two faces side by side, one black, one white. The officers who were “primed” to think about crime looked more at the black face.
The same stereotype, she discovered, affects perceptions of physical movement. Analyzing data from the New York Police Department, Eberhardt learned that black men were far more likely than white men to have been stopped for engaging in what’s called “furtive movement” — suspicious behavior like fidgeting with something at your waistline. Yet among those stopped, whites more often had a weapon.
The stereotype that black men are involved in crime led the police to perceive danger and illegality when there was none. Eberhardt connects the dots to national statistics showing that unarmed African-Americans are killed by the police at a higher rate than unarmed whites.
The experiments and observational studies reported in “Biased” are important and illuminating. They’re brought to life by stories from Eberhardt’s own experience.
Early in the book, for example, she writes about moving, when she was 12, from a mostly black neighborhood to a white suburb. Eberhardt, who is African-American, describes the difficulties she faced in her new school telling her white classmates apart. (The experience got her interested in how people identify faces.) A police stop in Boston in the early 1990s that turned ugly, on the eve of her graduation from Harvard with a Ph.D., recommitted her to studying the psychology of bias and the roots of police violence.
When she tells of teaching a class inside San Quentin prison, where she was forced to confront her own biases, or recounts conversations with her children about prejudice, we glimpse what it’s like to be her: a scholar of race who is still sometimes taken aback by its pervasiveness and power.
The book has one weakness. Eberhardt doesn’t spend much time on alternative hypotheses. Implicit bias isn’t the only way to think about the encounter in Boston between Antonio and Crossen, or the millions of other encounters that take place each year between citizens and the police.
To a sociologist, what stands out most about the exchange between the two men is that it was an exchange, an interaction, a back and forth. Many interactions are, in effect, “deference rituals.” When two people of unequal social status interact — for example, teacher/student, boss/employee or doctor/patient — it’s typical for the person of higher status to expect that deference be paid: that the lower-status person acknowledge his subordinate position, if only subtly, through speech or behavior.
In a classic article from 1975, the sociologists Richard Sykes and John Clark drew out the implications for police-minority relations. In a racially unequal society, whites (who predominate in law enforcement) may see themselves as occupying a higher rung than people of color. Cops, whatever their race, see themselves as symbols of law and the upstanding members of their community. So they expect deference — and may be more inclined to stop and question people from lower-status groups from whom they think they can command it.
But citizens who have endured mistreatment from the police in the past may be in no mood to defer. And why should they have to be more deferential than anyone else? Conflict results; the exchange between Crossen and Antonio is a case in point. Some police officers interpret anything other than docility as a challenge to their authority, even an indication of danger or guilt.
At the same time, as the sociologist Nikki Jones has shown, when people stopped frequently by the police learn to display complete deference — for example, submitting themselves to pat-downs without complaint, perhaps heeding the advice of parents who have given them “the talk” — they pay for it in self-esteem. It’s no-win.
Prompted in part by Eberhardt’s research, law enforcement agencies have been investing in training designed to counteract implicit bias and reduce racial disparities. A broader approach focused on unraveling the twisted social logic of deference could bring real benefits too.