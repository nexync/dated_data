Opinion|We Are a New Board Overseeing Facebook. Here’s What We’ll Decide.
We Are a New Board Overseeing Facebook. Here’s What We’ll Decide.
The company’s independent oversight body will focus on challenging content issues, such as hate speech and harassment.
The authors are co-chairs of Facebook’s oversight board.
Social media affects people’s lives in many ways, good and bad. Right now, as the world endures a health crisis, social media has become a lifeline for many people, providing valuable information and helping families and communities stay connected.
At the same time, we know that social media can spread speech that is hateful, harmful and deceitful. In recent years, the question of what content should stay up or come down on platforms like Facebook, and who should decide this, has become increasingly urgent.
So in November 2018, recognizing that no company should settle these issues alone, Facebook committed to creating an independent oversight body that will review Facebook’s decisions about what content to take down or leave up. Over the past 18 months, more than 2,000 experts and other relevant parties from 88 countries have contributed feedback that has shaped the development of this oversight board, which will have 20 members (ultimately growing to 40) and is scheduled to become operational this year.
The oversight board will focus on the most challenging content issues for Facebook, including in areas such as hate speech, harassment, and protecting people’s safety and privacy. It will make final and binding decisions on whether specific content should be allowed or removed from Facebook and Instagram (which Facebook owns).
Today, the first set of members of the oversight board is being announced. We are the four co-chairs. After Facebook selected us, we considered a large number of individuals for the oversight board, including those recommended by the public, before we interviewed and ultimately approved the 16 other members being announced today.
Our independent judgment is guaranteed by our structure. The oversight board’s operations are funded by a $130 million trust fund that is completely independent of Facebook and cannot be revoked. Board members will serve fixed terms of three years, up to a maximum of three terms; they contract directly with the oversight board. We cannot be removed by Facebook. Through the founding bylaws of the oversight board, Facebook has committed to carrying out our decisions even though it may at times disagree, unless doing so would violate the law. Facebook’s chief executive, Mark Zuckerberg, has also personally committed to this arrangement.
The entire process is designed with transparency in mind. All of the oversight board’s decisions and recommendations will be made public, and Facebook must respond publicly to them.
Over the coming months, we will lay out how we prioritize and select cases for review. Once a case has been chosen, it will be considered by a panel with a rotating set of members. All panel decisions will be reviewed by the entire board before they are finalized, and if a majority of members disagree with a decision, they can ask a new panel to hear the case again.
The oversight board cannot, of course, address every concern that people may have with Facebook. Policymakers, regulators and those who have a stake in the effects of technology on our society all continue to have a critical role to play. We also know that we will not be able to please everyone. Some of our decisions may prove controversial and all will spur further debate.
But we speak for all the members of the oversight board when we say that we are committed to demonstrating the value of an independent, principled and transparent oversight process and to serving the online community.
Catalina Botero-Marino is a former special rapporteur on freedom of expression of the Organization of the American States. Jamal Greene is a law professor at Columbia. Michael W. McConnell is a law professor at Stanford. Helle Thorning-Schmidt is a former prime minister of Denmark.