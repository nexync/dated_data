The Upshot|We’re Bad at Evaluating Risk. How Doctors Can Help.
What to do when we don’t know what to do.
My patient and I were locked in a game of decision-making hot potato.
“What would you do, Doc?” he said. 
Such questions trouble most doctors. We often lob the choice back to patients, or “on the one hand, on the other hand” so much that they start sympathizing with Harry Truman, who reportedly joked he wished for one-handed advisers.
But the evidence wasn’t clear. I passed the potato back.
Research suggests that physicians’ recommendations powerfully influence how patients weigh their choices, and that while almost all patients want to know their options, most want their doctor to make the final decision. The greater the uncertainty, the more support they want — but the less likely they are to receive it.
Doctors could be more aware of how their language affects patients. It’s easier for patients to understand absolute risks than relative risks: that treatment reduces your risk to 3 percent from 4 percent, instead of by 25 percent. Patients are more sensitive to harms than benefits, but doctors tend to dwell on the upside. Presenting choices sequentially instead of all at once seems to improve comprehension. And patients feel more confident in doctors who offer a rationale for uncertainty — describing the possible diagnoses even if the right one is unclear — than when they simply acknowledge it without explanation.
People in general are not great at evaluating risk. They worry more about shark attacks than car crashes.
Patients and doctors contend with two major forms of uncertainty: uncertainty of evidence and uncertainty of outcome.
Uncertainty of evidence is an information problem. It’s like putting a quarter into a gumball machine and having no idea how many will come out. Maybe there aren’t good clinical trials; maybe there are trials but they don’t include patients like you; maybe they do include patients like you but not while you’re fighting pneumonia.
Uncertainty of outcome is a prediction problem. We know five gumballs are coming out: We just don’t know which ones. Let’s say 5 percent of patients like you will have a stroke this year. Are you the 5 percent or the 95 percent?
Doctors typically recommend for or against treatment by dividing a continuum of risk into categories that trip a switch: a statin when you reach a 7.5 percent risk of a heart attack, a blood thinner when you’re at 2 percent risk of a stroke.
We’re less well trained to explore how a patient’s fears and values intersect with the available evidence. Maybe the inconvenience of daily pills makes a 10 percent risk of a heart attack acceptable to one patient, while a loved one’s recent illness makes a 1 percent risk of a stroke unacceptable to another.
In many cases, patient preferences diverge substantially from guideline recommendations, which are created by researchers and policymakers with little input from patients on where to draw the line of acceptable risk. But it’s in using these guidelines that doctors make their strongest recommendations, while shying away from decisions where evidence is limited, and where their clinical experience and intuition may be most valuable.
It’s easy to assume that innovations like machine learning and precision medicine will reduce uncertainty. But medical advances often generate more uncertainty, not less. Increasingly sophisticated imaging means we pick up more growths. More powerful lab tests uncover hidden — and possibly irrelevant — irregularities. When should we poke and prod? When should we watch and wait? As procedures become less invasive, more patients can get them: We can put stents in many more people than we can subject to open-heart surgery. But should we?
How can we help patients navigate the gray space?
Decision aids and risk pictographs can help patients better understand their values and their choices. But they’re available only for select conditions, and more useful for uncertainty of outcome than uncertainty of evidence: You have to know roughly how many gumballs are coming out.
A broader approach involves helping patients systematically identify what’s important to them, and based on these goals and preferences, suggesting to them how to think about their options. A program at the University of California, San Francisco, for example, coaches patients through a decision-making process known as Scoped: situation, choices, objectives, people, evaluation and decisions. Walking patients through each of these considerations can improve patient knowledge and satisfaction, and reduce anxiety and regret.
Patients need to understand their values but also their possible futures — which is where clinicians’ experience and guidance may be most valuable. Other industries sometimes use a technique known as scenario planning to prepare people for uncertain outcomes, and some argue this approach could be used in medicine as well. The idea is not to reduce uncertainty, but to help patients clearly envision what life would look like in one outcome versus another, and to better prepare them for the various futures that might unfold.
Training doctors to accept and convey uncertainty may also be needed. Doctors uncomfortable with uncertainty are more likely to experience work-related stress; withhold information from patients; and order more tests, procedures and referrals. There’s currently wide variation in what doctors believe their role should be when communicating uncertainty, and little instruction in how to do so.
What’s certain is that uncertainty will always be with us. When wading through medicine’s expansive gray zones, patients could use a guide. Will they get one?
Dhruv Khullar, M.D., M.P.P., is a physician at NewYork-Presbyterian Hospital, a researcher at the Weill Cornell Department of Healthcare Policy and Research, and director of policy dissemination at the Physicians Foundation Center for Physician Practice and Leadership. Follow him on Twitter: @DhruvKhullar.